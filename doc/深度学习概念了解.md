# 机器学习基础
## 学习算法
1. **无监督算法**：
数据集中没有一个明确的标识，需要机器自己学习找出内在的规律或结构
2. **监督算法**：
数据集中的数据有一个明确的标识，机器可以通过输入的x和标识y，推理其中的关系

>无监督学习涉及到观察随机向量 x 的好几个样本，试图显式或隐式地学习出概率分布 p(x)，或者是该分布一些有意思的性质；而监督学习包含观察随机向量 x 及其相关联的值或向量 y，然后从 x 预测 y，通常是估计 p(y | x)。术语监督学习（supervised learning）源自这样一个视角，教员或者老师提供目标 y 给机器学习系统，指导其应该做什么。在无监督学习中，没有教员或者老师，算法必须学会在没有指导的情况下理解数据。
3. **泛化**
在先前未观测到的输入上表现良好的能力被称为**泛
化**
4. **欠拟合**
模型不能在训练集上获得足够低的误差
5. **过拟合**
训练误差和测试误差之间的差距太大
6. **容量**
模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集，容量高的模型可能会过于拟合，因为记住了不适用于测试集的训练集性质。
7. **贝叶斯误差**
从预先知道的真实分布预测而出现的误差被称为贝叶斯误差。

## 深度前馈网络
1. **深度前馈网络**也叫做**前馈神经网络**或者**多层感知机**。前馈神经网络之所以叫做网络，是因为里面可以包含很多函数进行计算，通常使用链式结构。这些函数的最后一层被称为**输出层**，它必须产生一个近似目标y的值。中间这些层的所需输出并没有被数据集指定，所以这些层被称为**隐藏层**。
2. **反向传播**
反向传播允许来自代价函数的信息通过网络向后流动，以便计算梯度。

## 深度学习中的正则化
1. **正则化**
对学习算法的修改——旨在减少泛化误差而不是训练误差。
2. **Dropout**

