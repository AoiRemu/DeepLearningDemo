# 模型
## 弱智吧问答模型
### SEQ2SEQ 
1. 通过copilot,kimi等AI生成的代码进行训练
效果很差，AI给出的代码基本不能直接使用，有各种报错。
2. huggingface上的博客代码
效果不错，代码直接可以使用，且训练出的AI有明显提高：https://huggingface.co/blog/warm-starting-encoder-decoder

## COSPLAY聊天模型
### Causal
因果语言模型才是用于聊天的模型
huggingface学习：https://huggingface.co/learn/nlp-course/zh-CN/chapter7/6
1. CausalLM
模型太大，需要显卡才能跑
2. Lingzhi-AI
有小型的模型，但使用CPU跑还是太慢了，0.5B版本的跑一次大概十分钟
3. zxbsmk/NSFW_13B_sft
无限制的模型，可以续写白洁，估计也能用来虚拟COS
https://huggingface.co/zxbsmk/NSFW_13B_sft
他们有社区，电报：https://t.me/+JbovpBG6-gBiNDI1

# 训练记录
## 2024-09-11
- 弱智吧模型，用最初始的版本，使用爬虫的数据集多训几轮试试
## 2024-09-13
- RWKV模型使用：安装好环境跑是能跑，但加载模型的时候就报错，问题在于pytorch版本有冲突，得等下一批流量好了再重新配置环境试试
- 弱智吧模型训练：好像是用上了GPU，但速度没想象中那么快，训练完也得10分钟。爬虫的数据集有问题，里面有30多条“我是智障”的回答，所以导致模型动不动就说我是智障。将这部分脏数据删除后训练看看。
- **★**llama-3-8B：光是运行就特别慢，也不知道问题在哪，得好好看看